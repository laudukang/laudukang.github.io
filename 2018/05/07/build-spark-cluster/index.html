<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


<link href="/lib/nprogress/nprogress.css" rel="stylesheet" type="text/css" />








<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.3">


  <link rel="mask-icon" href="/images/favicon.png?v=5.1.3" color="#222">





  <meta name="keywords" content="spark" />










<meta name="description" content="Install pssh, to batch config spark slaves1234567wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.coms/parallel-ssh/pssh-2.3.1.t">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Build spark cluster">
<meta property="og:url" content="https://codz.me/2018/05/07/build-spark-cluster/index.html">
<meta property="og:site_name" content="Code Is Poetry">
<meta property="og:description" content="Install pssh, to batch config spark slaves1234567wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.coms/parallel-ssh/pssh-2.3.1.tar.gztar -xzvf pssh-2.3.1.tar.gzcd pssh-">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://nat.oss-cn-hongkong.aliyuncs.com/images/2018/05/07/build-spark-cluster/spark-worker-ui-hostname.png">
<meta property="og:updated_time" content="2018-06-09T07:00:52.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Build spark cluster">
<meta name="twitter:description" content="Install pssh, to batch config spark slaves1234567wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.coms/parallel-ssh/pssh-2.3.1.tar.gztar -xzvf pssh-2.3.1.tar.gzcd pssh-">
<meta name="twitter:image" content="https://nat.oss-cn-hongkong.aliyuncs.com/images/2018/05/07/build-spark-cluster/spark-worker-ui-hostname.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://codz.me/2018/05/07/build-spark-cluster/"/>




<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-8069999780024986",
    enable_page_level_ads: true
  });
</script>

  <title>Build spark cluster | Code Is Poetry</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f286ee7ebbe4dd6dfe2457f73f042ac0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Code Is Poetry</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            Commonweal 404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://codz.me/2018/05/07/build-spark-cluster/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="laudukang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Code Is Poetry">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">Build spark cluster</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-07T17:47:03+08:00">
                2018-05-07 17:47:03
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2018-06-09T15:00:52+08:00">
                2018-06-09 15:00:52
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/05/07/build-spark-cluster/" class="leancloud_visitors" data-flag-title="Build spark cluster">
                
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Install-pssh-to-batch-config-spark-slaves"><a href="#Install-pssh-to-batch-config-spark-slaves" class="headerlink" title="Install pssh, to batch config spark slaves"></a>Install pssh, to batch config spark slaves</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.coms/parallel-ssh/pssh-2.3.1.tar.gz</span><br><span class="line"></span><br><span class="line">tar -xzvf pssh-2.3.1.tar.gz</span><br><span class="line"></span><br><span class="line">cd pssh-2.3.1</span><br><span class="line"></span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>
<p>使用参见：</p>
<ul>
<li><p><a href="http://www.cnblogs.com/lurenjiashuo/p/pssh.html" target="_blank" rel="noopener">使用PSSH批量操作Linux服务器</a></p>
</li>
<li><p><a href="https://tonydeng.github.io/2014/12/08/pssh/" target="_blank" rel="noopener">PSSH基本使用介绍</a></p>
</li>
</ul>
<h2 id="System-config-in-master"><a href="#System-config-in-master" class="headerlink" title="System config in master"></a>System config in master</h2><p>/work/hosts</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@192.168.4.210</span><br><span class="line">root@192.168.4.211</span><br><span class="line">root@192.168.4.212</span><br><span class="line">root@192.168.4.213</span><br><span class="line">root@192.168.4.214</span><br><span class="line">root@192.168.4.215</span><br><span class="line">root@192.168.4.216</span><br><span class="line">root@192.168.4.217</span><br></pre></td></tr></table></figure>
<p>/etc/hosts</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1       localhost</span><br><span class="line">127.0.1.1       ubuntu</span><br><span class="line"></span><br><span class="line"># The following lines are desirable for IPv6 capable hosts</span><br><span class="line">::1     localhost ip6-localhost ip6-loopback</span><br><span class="line">ff02::1 ip6-allnodes</span><br><span class="line">ff02::2 ip6-allrouters</span><br><span class="line"></span><br><span class="line">192.168.4.211 n1</span><br><span class="line">192.168.4.212 n2</span><br><span class="line">192.168.4.213 n3</span><br><span class="line">192.168.4.214 n4</span><br><span class="line">192.168.4.215 n5</span><br><span class="line">192.168.4.216 n6</span><br><span class="line">192.168.4.217 n7</span><br></pre></td></tr></table></figure>
<p>/etc/environment</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">LANGUAGE=&quot;zh_CN:zh:en_US:en&quot;</span><br><span class="line">LANG=zh_CN.GBK</span><br><span class="line">SPARK_HOME=/work/spark</span><br><span class="line">SCALA_HOME=/opt/scala</span><br><span class="line">JAVA_HOME=/opt/java</span><br><span class="line">J2SDKDIR=/opt/java</span><br><span class="line">J2REDIR=/opt/java/jre</span><br><span class="line">DERBY_HOME=/opt/java/db</span><br><span class="line">PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/opt/java/bin:/opt/scala/bin:/work/spark/bin&quot;</span><br><span class="line">CLASSPATH=..:/opt/java/lib:/opt/java/jre/lib:/opt/scala/lib:/work/spark/jars</span><br></pre></td></tr></table></figure>
<p>/work/spark/conf/spark-env.sh,update <code>ens3</code> to your network interface</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_LOCAL_IP=$(ifconfig ens3 | grep "inet addr:" | awk '&#123;print $2&#125;' | cut -c 6-)</span><br><span class="line">export SPARK_MASTER_HOST=n1</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line">export SPARK_MASTER_WEBUI_PORT=8000</span><br><span class="line">export SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=/work/spark/logs-event"</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> SPARK_EXECUTOR_CORES=1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> SPARK_EXECUTOR_MEMORY=512M</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> SPARK_WORKER_INSTANCES=4</span></span><br></pre></td></tr></table></figure>
<p>update_hostname.sh, update default hostname <code>ubuntu</code> to <code>n{machine ip last number}</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/usr/bin/env bash</span></span><br><span class="line">NODE_LOCAL_IP=$(ifconfig ens3 | grep "inet addr:" | awk '&#123;print $2&#125;' | cut -c 6-)</span><br><span class="line">NEW_HOSTNAME="n$&#123;NODE_LOCAL_IP:12&#125;"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="variable">$NEW_HOSTNAME</span> &gt; /proc/sys/kernel/hostname</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="variable">$NEW_HOSTNAME</span> &gt; /etc/hostname</span></span><br><span class="line"></span><br><span class="line">sed -i 's/127.0.1.1.*/127.0.1.1\t'"$NEW_HOSTNAME"'/g' /etc/hosts</span><br><span class="line">hostnamectl set-hostname $NEW_HOSTNAME</span><br></pre></td></tr></table></figure>
<h2 id="Init-master-and-slaves-in-master"><a href="#Init-master-and-slaves-in-master" class="headerlink" title="Init master and slaves in master"></a>Init master and slaves in master</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">pssh -h hosts "apt update"</span><br><span class="line">pssh -h hosts "apt install htop -y"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">zsh init</span></span><br><span class="line">pssh -h hosts "apt install zsh -y"</span><br><span class="line">pssh -h hosts 'sh -c "$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)";'</span><br><span class="line">pssh -h hosts chsh -s $(which zsh)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">update dns resolve</span></span><br><span class="line">pscp -h hosts /etc/resolvconf/resolv.conf.d/base /etc/resolvconf/resolv.conf.d/base</span><br><span class="line">pssh -h hosts "resolvconf -u"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">host update</span></span><br><span class="line">pscp -h hosts /etc/hosts /etc</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">create work directory</span></span><br><span class="line">pssh -h hosts "mkdir /work"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">copy from master: 192.168.4.210</span></span><br><span class="line"><span class="meta">#</span><span class="bash">plesae remove 192.168.4.210 <span class="keyword">in</span> hosts</span></span><br><span class="line"></span><br><span class="line">tar -zxvf jdk-8u172-linux-x64.tar.gz -C /opt</span><br><span class="line">tar -zxvf scala-2.11.12.tgz -C /opt</span><br><span class="line">tar -zxvf scala-2.11.12.tgz -C /opt</span><br><span class="line">mv /opt/jdk-8u172-linux-x64 /opt/java</span><br><span class="line">mv /opt/scala-2.11.12 /opt/scala</span><br><span class="line"></span><br><span class="line">tar -zxvf spark-2.3.0-bin-hadoop2.7.tgz -C /work</span><br><span class="line">mv spark-2.3.0-bin-hadoop2.7 spark</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">copy java, scala</span></span><br><span class="line">pscp -r -h hosts /opt/* /opt/</span><br><span class="line"><span class="meta">#</span><span class="bash">copy spark</span></span><br><span class="line">pscp -r -h hosts /work/spark /work</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">update env variables</span></span><br><span class="line">pscp -h hosts /etc/environment /etc</span><br><span class="line">pssh -h hosts "source /etc/environment"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">update hostname</span></span><br><span class="line">pscp -h hosts update_hostname.sh /tmp/</span><br><span class="line">pssh -h hosts "./tmp/update_hostname.sh"</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop-config-in-master"><a href="#Hadoop-config-in-master" class="headerlink" title="Hadoop config in master"></a>Hadoop config in master</h2><p>此处引入<code>hadoop</code>是为了slaves从<code>hadoop</code>拉去资源启动app；</p>
<p>当然，也可以复制jar到各slaves相同的路径启动；</p>
<p>后面发现，每次重启app，spark都会从<code>hadoop</code>全量拉取一遍资源到<code>spark/work</code>目录。</p>
<p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="php"><span class="meta">&lt;?</span>xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span><span class="meta">?&gt;</span></span></span><br><span class="line"><span class="php"><span class="meta">&lt;?</span>xml-stylesheet type=<span class="string">"text/xsl"</span> href=<span class="string">"configuration.xsl"</span><span class="meta">?&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/work/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://n0:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="php"><span class="meta">&lt;?</span>xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span><span class="meta">?&gt;</span></span></span><br><span class="line"><span class="php"><span class="meta">&lt;?</span>xml-stylesheet type=<span class="string">"text/xsl"</span> href=<span class="string">"configuration.xsl"</span><span class="meta">?&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/work/hadoop/tmp/dfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/work/hadoop/tmp/dfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>n0:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.superusergroup<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.secondary.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>n0:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>n0:9864<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>n0:9866<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>n0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>init <code>hadoop</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">create hadoop user <span class="keyword">in</span> master</span></span><br><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">/work/hadoop/bin</span></span><br><span class="line">./hdfs dfs -mkdir -p /sparkHistoryLogs</span><br><span class="line">./hdfs dfs -mkdir -p /eventLogs</span><br><span class="line">./hdfs dfs -mkdir -p /spark</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">./hdfs dfs -rm -R /spark/app/*</span></span><br></pre></td></tr></table></figure>
<p>copy_app_resouces_to_hadoop.sh, run as <code>hadoop</code> user</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">cd /work/hadoop/bin</span><br><span class="line"><span class="meta">#</span><span class="bash">./hdfs dfs -mkdir -p /spark</span></span><br><span class="line">./hdfs dfs -rm -R /spark/app/*</span><br><span class="line">./hdfs dfs -copyFromLocal -f /work/spark/app/log4j.properties /spark/app</span><br><span class="line"><span class="meta">#</span><span class="bash">spark config</span></span><br><span class="line">./hdfs dfs -copyFromLocal -f /work/spark/app/default.conf /spark/app</span><br><span class="line"><span class="meta">#</span><span class="bash">app dependencies</span></span><br><span class="line">./hdfs dfs -copyFromLocal -f /work/spark/app/lib /spark/app</span><br><span class="line">./hdfs dfs -copyFromLocal -f /work/spark/app/node-quality-streaming-0.0.1-SNAPSHOT.jar /spark/app</span><br></pre></td></tr></table></figure>
<h2 id="Exception-solutions"><a href="#Exception-solutions" class="headerlink" title="Exception solutions"></a>Exception solutions</h2><ul>
<li><p>fix spark WorkWebUI hostname(logs) 指向master机器hostname</p>
<p>看源码，在<code>spark-env.sh</code>中指定<code>SPARK_LOCAL_HOSTNAME</code>并没起作用，</p>
<p>解决方案：设置<code>SPARK_PUBLIC_DNS</code>参数后，worker webui中的跳转链接正常了。</p>
<p><code>SPARK_PUBLIC_DNS</code>→<code>publicHostName</code>我也是服了，</p>
<p>如下图，原先<code>stdout</code>的链接的的主机为<code>n0</code>，<code>n0</code>为master所在的机器：</p>
<img src="https://nat.oss-cn-hongkong.aliyuncs.com/images/2018/05/07/build-spark-cluster/spark-worker-ui-hostname.png" alt="spark-worker-ui-hostname.png" title="">
<p>源码参考</p>
<p><a href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/ui/WebUI.scala" target="_blank" rel="noopener">core/src/main/scala/org/apache/spark/ui/WebUI.scala</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> publicHostName = <span class="type">Option</span>(conf.getenv(<span class="string">"SPARK_PUBLIC_DNS"</span>)).getOrElse(</span><br><span class="line">    conf.get(<span class="type">DRIVER_HOST_ADDRESS</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Return the url of web interface. Only valid after bind(). */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">webUrl</span></span>: <span class="type">String</span> = <span class="string">s"http://<span class="subst">$publicHostName</span>:<span class="subst">$boundPort</span>"</span></span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/util/Utils.scala" target="_blank" rel="noopener">core/src/main/scala/org/apache/spark/util/Utils.scala</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> localIpAddress: <span class="type">InetAddress</span> = findLocalInetAddress()</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> customHostname: <span class="type">Option</span>[<span class="type">String</span>] = sys.env.get(<span class="string">"SPARK_LOCAL_HOSTNAME"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Get the local machine's URI.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">localHostNameForURI</span></span>(): <span class="type">String</span> = &#123;</span><br><span class="line">  customHostname.getOrElse(<span class="type">InetAddresses</span>.toUriString(localIpAddress))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>spark ConsumerRecord NotSerializableException bug</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">java.io.NotSerializableException: org.apache.kafka.clients.consumer.ConsumerRecord</span><br><span class="line">Serialization stack:</span><br><span class="line">    - <span class="function">object not <span class="title">serializable</span> <span class="params">(class: org.apache.kafka.clients.consumer.ConsumerRecord, value: ConsumerRecord(topic = hi2, partition = <span class="number">4</span>, offset = <span class="number">385</span>, CreateTime = <span class="number">1526369397516</span>, checksum = <span class="number">2122851237</span>, serialized key size = <span class="number">-1</span>, serialized value size = <span class="number">45</span>, key = <span class="keyword">null</span>, value = &#123;<span class="string">"date"</span>:<span class="number">1526369397516</span>,<span class="string">"message"</span>:<span class="string">"0hh2KcCH4j"</span>&#125;)</span>)</span></span><br><span class="line"><span class="function">    - element of <span class="title">array</span> <span class="params">(index: <span class="number">0</span>)</span></span></span><br><span class="line"><span class="function">    - <span class="title">array</span> <span class="params">(class [Lorg.apache.kafka.clients.consumer.ConsumerRecord;, size <span class="number">125</span>)</span></span></span><br><span class="line"><span class="function">    at org.apache.spark.serializer.SerializationDebugger$.<span class="title">improveException</span><span class="params">(SerializationDebugger.scala:<span class="number">40</span>)</span></span></span><br><span class="line"><span class="function">    at org.apache.spark.serializer.JavaSerializationStream.<span class="title">writeObject</span><span class="params">(JavaSerializer.scala:<span class="number">46</span>)</span></span></span><br><span class="line"><span class="function">    at org.apache.spark.serializer.JavaSerializerInstance.<span class="title">serialize</span><span class="params">(JavaSerializer.scala:<span class="number">100</span>)</span></span></span><br><span class="line"><span class="function">    at org.apache.spark.executor.Executor$TaskRunner.<span class="title">run</span><span class="params">(Executor.scala:<span class="number">393</span>)</span></span></span><br><span class="line"><span class="function">    at java.util.concurrent.ThreadPoolExecutor.<span class="title">runWorker</span><span class="params">(ThreadPoolExecutor.java:<span class="number">1149</span>)</span></span></span><br><span class="line"><span class="function">    at java.util.concurrent.ThreadPoolExecutor$Worker.<span class="title">run</span><span class="params">(ThreadPoolExecutor.java:<span class="number">624</span>)</span></span></span><br><span class="line"><span class="function">    at java.lang.Thread.<span class="title">run</span><span class="params">(Thread.java:<span class="number">748</span>)</span></span></span><br></pre></td></tr></table></figure>
<p>解决方案</p>
<p>set SparkConf</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sparkConf.set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>);</span><br><span class="line">sparkConf.set(<span class="string">"spark.kryo.registrator"</span>, <span class="string">"me.codz.registrator.CunstomRegistrator"</span>);</span><br></pre></td></tr></table></figure>
<p>create CunstomRegistrator</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> me.codz.registrator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.esotericsoftware.kryo.Kryo;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.serializer.KryoRegistrator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CunstomRegistrator</span> <span class="keyword">implements</span> <span class="title">KryoRegistrator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerClasses</span><span class="params">(Kryo kryo)</span> </span>&#123;</span><br><span class="line">        kryo.register(ConsumerRecord.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>spark TaskContext.get() cause NullPointerException</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">stream.foreachRDD((VoidFunction2&lt;JavaRDD&lt;ConsumerRecord&lt;String, String&gt;&gt;, Time&gt;) (v1, v2) -&gt; &#123;</span><br><span class="line">           OffsetRange[] offsetRanges = ((HasOffsetRanges) v1.rdd()).offsetRanges();</span><br><span class="line"></span><br><span class="line">           List&lt;ConsumerRecord&lt;String, String&gt;&gt; consumerRecordList = CollectionTools.emptyWrapper(v1.collect());</span><br><span class="line">           consumerRecordList.forEach(consumerRecord -&gt; &#123;</span><br><span class="line">               TaskContext taskContext = TaskContext.get();</span><br><span class="line">               <span class="keyword">int</span> partitionId = taskContext.partitionId();</span><br><span class="line">               OffsetRange o = offsetRanges[partitionId];</span><br><span class="line"></span><br><span class="line">               <span class="comment">//...</span></span><br><span class="line">           &#125;);</span><br><span class="line"></span><br><span class="line">       &#125;);</span><br></pre></td></tr></table></figure>
<p>解决方案<br>using <code>foreachPartition</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">v1.foreachPartition(consumerRecordIterator -&gt; &#123;</span><br><span class="line">                <span class="keyword">while</span> (consumerRecordIterator.hasNext()) &#123;</span><br><span class="line">                    ConsumerRecord&lt;String, String&gt; consumerRecord = consumerRecordIterator.next();</span><br><span class="line"></span><br><span class="line">                    <span class="comment">//...</span></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                TaskContext taskContext = TaskContext.get();</span><br><span class="line">                <span class="keyword">int</span> partitionId = taskContext.partitionId();</span><br><span class="line">                OffsetRange offsetRange = offsetRanges[partitionId];</span><br><span class="line"></span><br><span class="line">                <span class="comment">//...</span></span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure>
</li>
<li><p>Spark app connect kafka server by ip suspend</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2018-06-07 18:40:16 [ForkJoinPool-1-worker-5] INFO :: [Consumer clientId=consumer-1, groupId=node-quality-streaming] Discovered group coordinator lau.cc:9092 (id: 2147483647 rack: null)</span><br><span class="line">2018-06-07 18:40:18 [ForkJoinPool-1-worker-5] INFO :: [Consumer clientId=consumer-1, groupId=node-quality-streaming] Group coordinator lau.cc:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery</span><br></pre></td></tr></table></figure>
<p>解决方案</p>
<p>vim kafka/config/server.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#add follow line</span><br><span class="line">advertised.host.name=192.168.3.20</span><br></pre></td></tr></table></figure>
<p>kafka <code>advertised.host.name</code> DEPRECATED since 0.10.x, <a href="https://kafka.apache.org/0100/documentation.html#brokerconfigs" target="_blank" rel="noopener">0100 brokerconfigs</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DEPRECATED: only used when `advertised.listeners` or `listeners` are not set. Use `advertised.listeners` instead. Hostname to publish to ZooKeeper for clients to use. In IaaS environments, this may need to be different from the interface to which the broker binds. If this is not set, it will use the value for `host.name` if configured. Otherwise it will use the value returned from java.net.InetAddress.getCanonicalHostName().</span><br></pre></td></tr></table></figure>
<p>so follow config can also take effect</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">listeners=PLAINTEXT://192.168.3.20:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://192.168.3.20:9092</span><br></pre></td></tr></table></figure>
</li>
<li><p>mark</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java.lang.OutOfMemoryError: unable to create new native thread</span><br><span class="line"></span><br><span class="line">Offsets out of range with no configured reset policy for partitions</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Zookeeper-cluster-init"><a href="#Zookeeper-cluster-init" class="headerlink" title="Zookeeper cluster init"></a>Zookeeper cluster init</h2><p><a href="https://www.apache.org/dyn/closer.cgi/zookeeper/" target="_blank" rel="noopener">Download package from here</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.12.tar.gz -C /work</span><br><span class="line">mv zookeeper-3.4.12 zookeeper</span><br><span class="line"></span><br><span class="line">cp conf/zoo_sample.cfg conf/zoo.cfg</span><br></pre></td></tr></table></figure>
<p>vim conf/zoo.cfg</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/work/zookeeper/data</span><br><span class="line">clientPort=2181</span><br><span class="line"></span><br><span class="line">server.0=192.168.4.210:2888:3888</span><br><span class="line">server.1=192.168.4.211:2888:3888</span><br><span class="line">server.2=192.168.4.212:2888:3888</span><br><span class="line">server.3=192.168.4.213:2888:3888</span><br><span class="line">server.4=192.168.4.214:2888:3888</span><br><span class="line">server.5=192.168.4.215:2888:3888</span><br><span class="line">server.6=192.168.4.216:2888:3888</span><br><span class="line">server.7=192.168.4.217:2888:3888</span><br></pre></td></tr></table></figure>
<p>bin/init_myid.sh, update <code>ens3</code> to your network interface</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">NODE_LOCAL_IP=$(ifconfig ens3 | grep "inet addr:" | awk '&#123;print $2&#125;' | cut -c 6-)</span><br><span class="line">echo $&#123;NODE_LOCAL_IP##*.&#125; &gt; /work/zookeeper/data/myid</span><br></pre></td></tr></table></figure>
<p>init cluster myid</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pssh -h /work/hosts "/work/zookeeper/bin/init_myid.sh"</span><br></pre></td></tr></table></figure>
<p>start zookeeper cluster</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pssh -h /work/hhosts -o out "/work/zookeeper/bin/zkServer.sh start"</span><br></pre></td></tr></table></figure>
<h2 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h2><ul>
<li><p><a href="https://code.google.com/archive/p/parallel-ssh/downloads" target="_blank" rel="noopener">parallel-ssh download page</a></p>
</li>
<li><p><a href="https://www.iteblog.com/archives/2270.html" target="_blank" rel="noopener">Hadoop 2.x Port &amp; 3.x 多个服务的默认端口被改变</a></p>
</li>
<li><p><a href="https://hadoop.apache.org/docs/r3.1.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">hadoop r3.1.0 hdfs-default.xml</a></p>
</li>
<li><p><a href="https://stackoverflow.com/questions/47310619/cant-delete-hdfs-directory-via-web-interface-because-im-dr-who" target="_blank" rel="noopener">Can’t Delete HDFS Directory Via Web Interface Because I’m Dr. Who</a></p>
</li>
<li><p><a href="https://github.com/apache/spark/pull/11490/commits/d64ade1939e51bfa4da0958e1057164b725ad7f3" target="_blank" rel="noopener">[SPARK-13117] [Web UI] WebUI should use the local ip not 0.0.0.0 #11490</a></p>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"># spark</a>
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
            <a href="/tags/zookeeper/" rel="tag"># zookeeper</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/02/28/ssh-login-with-key-fail-and-require-password/" rel="next" title="用户目录权限问题导致 SSH 免密码登录失败">
                <i class="fa fa-chevron-left"></i> 用户目录权限问题导致 SSH 免密码登录失败
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/head.png"
                alt="laudukang" />
            
              <p class="site-author-name" itemprop="name">laudukang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">67</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://stackoverflow.com/users/5621049/laudukang" target="_blank" title="StackOverflow">
                    
                      <i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://github.com/laudukang" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://gitee.com/laudukang" target="_blank" title="Git@OSC">
                    
                      <i class="fa fa-fw fa-github-alt"></i>Git@OSC</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://my.oschina.net/laudukang" target="_blank" title="OSC">
                    
                      <i class="fa fa-fw fa-cube"></i>OSC</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://twitter.com/laudukang" target="_blank" title="Twitter">
                    
                      <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.v2ex.com/member/laudukang" target="_blank" title="V2EX">
                    
                      <i class="fa fa-fw fa-comments"></i>V2EX</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:laudukang@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.google.com/maps/place/%E6%B7%B1%E5%9C%B3%E5%B8%82%E8%BD%AF%E4%BB%B6%E4%BA%A7%E4%B8%9A%E5%9F%BA%E5%9C%B0/@22.5244896,113.9382973,17z/data=!3m1!4b1!4m5!3m4!1s0x3403ee17d008a019:0xbb7b06b73d856c14!8m2!3d22.5244896!4d113.9382973" target="_blank" title="Map">
                    
                      <i class="fa fa-fw fa-map-marker"></i>Map</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Install-pssh-to-batch-config-spark-slaves"><span class="nav-number">1.</span> <span class="nav-text">Install pssh, to batch config spark slaves</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#System-config-in-master"><span class="nav-number">2.</span> <span class="nav-text">System config in master</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Init-master-and-slaves-in-master"><span class="nav-number">3.</span> <span class="nav-text">Init master and slaves in master</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-config-in-master"><span class="nav-number">4.</span> <span class="nav-text">Hadoop config in master</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Exception-solutions"><span class="nav-number">5.</span> <span class="nav-text">Exception solutions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Zookeeper-cluster-init"><span class="nav-number">6.</span> <span class="nav-text">Zookeeper cluster init</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考内容"><span class="nav-number">7.</span> <span class="nav-text">参考内容</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 - <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">laudukang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io" rel="external nofollow">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next" rel="external nofollow">NexT.Pisces</a> v5.1.3</div>




        
<div class="busuanzi-count" style="display: none;">
  <script async src="/js/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/nprogress/nprogress.js"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/custom/custom.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  








  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("CPfRDhOlTyfkHW155W3Kx3H1-gzGzoHsz", "TX05RQSQMd8fbL7RaJNADS7S");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

  

  

</body>
</html>
